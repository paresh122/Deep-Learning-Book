{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Convolutional layer\n",
    "    MaxPooling2D((2, 2)),                                            # Pooling layer\n",
    "    Flatten(),                                                       # Flattening layer\n",
    "    Dense(64, activation='relu'),                                    # Fully connected layer\n",
    "    Dense(10, activation='softmax')                                  # Output layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a convolutional layer with 32 filters, each of size 3x3. The 'relu' activation function introduces non-linearity, allowing the model to learn more complex patterns.The max pooling layer reduces the spatial dimensions (height and width) of the input volume, which helps in reducing computation and controlling overfittingFlattening transforms the 2D matrix data (output from the convolutional layers) into a 1D vector. This is necessary before feeding the data into the fully connected layers.A dense layer with 64 neurons is added to interpret the features extracted by the convolutional and pooling layers. The 'relu' activation function is used here as well.The output layer has 10 neurons (assuming 10 classes for classification), and uses the 'softmax' activation function to output a probability distribution over the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled with the 'adam' optimizer, and 'sparse_categorical_crossentropy' is used as the loss function, a common choice for multi-class classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
