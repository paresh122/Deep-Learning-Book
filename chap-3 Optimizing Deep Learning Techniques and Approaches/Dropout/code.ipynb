{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generating synthetic data\n",
    "X = np.array([[-1.58986e-01, 4.23977e-01],\n",
    "              [-3.47926e-01, 4.70760e-01],\n",
    "           â€¦\n",
    "            ])\n",
    "y = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
    "               ...\n",
    "             ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a dataset X containing 2D points and their corresponding labels y (binary labels: 0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=2, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are using a sequential model with three layers: two dense (fully connected) layers with ReLU activation functions, and one output layer with a sigmoid activation function (since it's binary classification).\n",
    "Dropout layers are added after the first and second dense layers to prevent overfitting. The dropout rate is set to 0.5, meaning that during each training epoch, 50% of the neurons in the dropout layers will be randomly \"dropped out\" (i.e., their outputs will be set to zero).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled using the Adam optimizer with a learning rate of 0.01 and binary cross-entropy as the loss function. Accuracy is used as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X, y, epochs=500, validation_split=0.2, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the data (X and y) for 500 epochs with a validation split of 20%. The training history is stored in the history variable."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
