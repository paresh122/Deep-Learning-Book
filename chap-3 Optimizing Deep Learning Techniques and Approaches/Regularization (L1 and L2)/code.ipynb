{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing necessary libraries such as NumPy, Matplotlib, Seaborn, and the required TensorFlow and Keras modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, y = make_moons(100, noise=0.25, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating a synthetic dataset using the make_moons function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(128, input_dim=2, activation=\"relu\", kernel_regularizer=tensorflow.keras.regularizers.l1(0.001)))\n",
    "model1.add(Dense(128, activation=\"relu\", kernel_regularizer=tensorflow.keras.regularizers.l1(0.001)))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines a neural network, `model1`, with two hidden layers using ReLU activation. L1 regularization is applied to the weights in each layer, controlled by the hyperparameter 0.001. This regularization helps prevent overfitting by penalizing large weight values, contributing to a more generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.01)\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled with the Adam optimizer, binary cross-entropy loss, and accuracy as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model2.fit(X, y, epochs=2000, validation_split=0.2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained on the generated data for 2000 epochs with a validation split of 20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
